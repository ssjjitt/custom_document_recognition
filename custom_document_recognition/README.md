# Custom Document Recognition

Современное веб-приложение для автоматического распознавания и извлечения данных из документов с использованием OCR и локальной LLM.

## Основные возможности

### Автоматическое распознавание документов
- **Автоматический режим**: ИИ самостоятельно определяет язык документа, распознает текст и предлагает поля для извлечения
- **Ручной режим**: Полный контроль над процессом распознавания - выбор языка и полей вручную
- **Многостраничные PDF**: Поддержка обработки многостраничных документов с пагинацией
- **Распознавание валют**: Автоматическое определение валюты в документе (RUB, USD, EUR, KZT, UAH)

### OCR (Оптическое распознавание символов)
- Высокая точность распознавания благодаря предобработке изображений
- Поддержка множества языков (русский, английский, немецкий, французский, испанский)
- Визуализация распознанных блоков текста с полигонами на каждом слове
- Отображение уверенности распознавания для каждого блока

### Извлечение данных с помощью LLM
- Интеграция с локальной LLM (Mistral через Ollama)
- Умное извлечение полей из документов
- Автоматическое предложение релевантных полей на основе содержимого документа
- AI-генерируемые описания полей для лучшего понимания

### Конструктор форм
- Гибкий конструктор для настройки полей извлечения
- Шаблоны полей для быстрого создания форм
- Интуитивный интерфейс с подсказками

### История и шаблоны
- Сохранение истории распознаваний
- Управление шаблонами полей
- Быстрая загрузка предыдущих результатов

### Современный UI/UX
- Красивый и интуитивный интерфейс
- Адаптивный дизайн
- Визуализация распознанных блоков с полигонами
- Пагинация для многостраничных документов
- Удобная навигация и управление

## Технологический стек

### Backend
- **Node.js** (>=18) + **TypeScript**
- **Express.js** - веб-сервер
- **Tesseract.js** - OCR движок
- **Sharp** - обработка изображений
- **pdf-lib** - работа с PDF
- **MongoDB** (опционально) - база данных
- **Ollama** (локальная LLM) - извлечение данных

### Frontend
- **React 19** + **TypeScript**
- **Vite** - сборщик и dev-сервер
- **Tailwind CSS** - стилизация
- **Axios** - HTTP клиент
- **React Toastify** - уведомления

## Установка

### Требования
- Node.js >= 18
- MongoDB (опционально, используется JSON fallback)
- Ollama с установленной моделью Mistral (для работы LLM)

### Установка зависимостей

```bash
# Backend
cd backend
npm install

# Frontend
cd ../frontend
npm install
```

### Настройка Ollama

Убедитесь, что Ollama запущен и модель Mistral установлена:

```bash
# Запуск Ollama (если еще не запущен)
ollama serve

# Установка модели Mistral (если еще не установлена)
ollama pull mistral
```

## Запуск

### Development режим

```bash
# Terminal 1 - Backend
cd backend
npm run dev

# Terminal 2 - Frontend
cd frontend
npm run dev
```

Backend будет доступен на `http://localhost:4000`
Frontend будет доступен на `http://localhost:3000` (настроено в vite.config.ts)

### Production режим

```bash
# Backend
cd backend
npm run build
npm start

# Frontend
cd frontend
npm run build
npm run preview
```

## Использование

1. **Загрузка документа**: Перетащите файл или выберите его через интерфейс (поддерживаются PDF, PNG, JPG, JPEG)

2. **Выбор режима**:
   - **Автоматический**: ИИ сам определит язык и предложит поля
   - **Ручной**: Выберите язык и поля вручную

3. **Распознавание**: Нажмите "Запустить распознавание"

4. **Работа с результатами**:
   - Просмотрите распознанные блоки текста с полигонами
   - Назначьте блоки нужным полям, кликнув на них
   - Просмотрите извлеченные данные в результатах
   - Сохраните шаблон для повторного использования

5. **Многостраничные документы**:
   - Используйте пагинацию для переключения между страницами
   - Блоки текста фильтруются по текущей странице

## Особенности интерфейса

- **Визуализация полигонов**: Каждое слово отображается в отдельном полигоне с читабельным текстом
- **Умные подсказки**: AI-генерируемые описания для полей и разделов интерфейса
- **История**: Просмотр и загрузка предыдущих результатов распознавания
- **Шаблоны**: Сохранение и использование шаблонов полей
- **Адаптивность**: Удобная работа на разных размерах экрана

## Конфигурация

### Backend конфигурация

Настройки путей находятся в `backend/src/utils/paths.ts`:
- `UPLOADS_DIR` - директория для загруженных файлов
- `LOGS_DIR` - директория для логов
- `TEMPLATES_DIR` - директория для шаблонов

Порт сервера настраивается через переменную окружения `PORT` (по умолчанию 4000)

### Frontend конфигурация

API базовый URL настраивается через переменную окружения `VITE_API_BASE` (по умолчанию `http://localhost:4000`)

Можно создать файл `.env` в папке `frontend`:
```
VITE_API_BASE=http://localhost:4000
```

### LLM конфигурация

URL для LLM по умолчанию: `http://localhost:11434/api/generate`

Можно изменить в `backend/src/services/llm.service.ts`

## API Endpoints

- `POST /api/upload` - Загрузка файла
- `POST /api/recognize` - Распознавание документа
- `GET /api/pages/:filePath/:pageNumber` - Получение страницы PDF
- `GET /api/history` - Получение истории
- `POST /api/templates` - Управление шаблонами
- `POST /api/assist/describe-field` - Описание поля через AI
- `GET /api/ping` - Проверка работоспособности сервера

## Структура проекта

```
custom_document_recognition/
├── backend/                    # Express.js сервер
│   ├── src/
│   │   ├── index.ts           # Точка входа сервера
│   │   ├── routes/            # API маршруты
│   │   │   ├── upload.route.ts
│   │   │   ├── recognize.route.ts
│   │   │   ├── history.route.ts
│   │   │   ├── templates.route.ts
│   │   │   ├── assist.route.ts
│   │   │   └── pages.route.ts
│   │   ├── services/          # Бизнес-логика
│   │   │   ├── ocr.service.ts
│   │   │   ├── llm.service.ts
│   │   │   ├── cache.service.ts
│   │   │   └── log.service.ts
│   │   ├── middleware/        # Middleware
│   │   │   └── errorHandler.ts
│   │   └── utils/             # Утилиты
│   │       ├── paths.ts
│   │       └── mongo.ts
│   ├── uploads/               # Загруженные файлы
│   ├── logs/                  # Логи приложения
│   ├── templates/             # Шаблоны полей
│   ├── eng.traineddata        # Данные для английского языка (Tesseract)
│   ├── rus.traineddata        # Данные для русского языка (Tesseract)
│   ├── package.json
│   └── tsconfig.json
│
└── frontend/                  # React приложение
    ├── src/
    │   ├── App.tsx            # Главный компонент
    │   ├── main.tsx           # Точка входа
    │   ├── api/
    │   │   └── client.ts      # Axios клиент
    │   ├── components/        # React компоненты
    │   │   ├── DocViewer.tsx
    │   │   ├── FileUploader.tsx
    │   │   ├── FormBuilder.tsx
    │   │   ├── ResultViewer.tsx
    │   │   ├── HistoryViewer.tsx
    │   │   ├── TemplateManager.tsx
    │   │   ├── LanguageSelector.tsx
    │   │   ├── SmartTooltip.tsx
    │   │   └── Tooltip.tsx
    │   ├── store/             # Состояние приложения
    │   └── index.css          # Глобальные стили
    ├── public/                # Статические файлы
    ├── package.json
    ├── vite.config.ts         # Конфигурация Vite
    ├── tailwind.config.js     # Конфигурация Tailwind
    └── tsconfig.json
```

## Известные ограничения

- Требуется локальная установка Ollama для работы LLM
- Для оптимальной работы с PDF рекомендуется установка Poppler (pdftoppm)
- Кэш OCR хранится во временной директории (24 часа TTL)
- MongoDB опциональна - используется JSON fallback для хранения данных

## Лицензия

ISC

## Разработка

Проект использует TypeScript для типобезопасности и современные практики разработки.

### Скрипты

**Backend:**
- `npm run dev` - запуск в development режиме
- `npm run build` - сборка проекта
- `npm start` - запуск production версии

**Frontend:**
- `npm run dev` - запуск dev-сервера (Vite)
- `npm run build` - сборка production версии
- `npm run preview` - предпросмотр production сборки

